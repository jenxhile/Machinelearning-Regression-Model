# -*- coding: utf-8 -*-
"""Teht3_osa2_Regressiomalli_JennaHilden.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NMVEbtrNxKoJL_GDSOzWHsKZZF9K8rzS

## Tehtävä 3 osa 2: regressiomalli

Tarkastelen dataa "Energy Efficiency" ENB2012_data.xlsx, joka sisältää tietoa kiinteistöjen energiatehokkuuteen vaikuttavista tekijöistä. Tehtävässä analysoidaan erityisesti sitä, miten hyvin selittävillä muuttujilla pystytään ennustamaan kohdemuuttujaa Y1 (Lämmityskuorma). Käytän analyysiin lineaarista regressiomallia ja pyrin analysoimaan, mitkä selittävistä muuttujista ovat merkitseviä ja kuinka toimiva kyseinen malli on ennustamiseen.
Aineiston lähde: https://archive.ics.uci.edu/dataset/242/energy+efficiency
## Taustaa

Lämmityskuorma (Heating Load) tässä yhteydessä tarkoittaa rakennuksen lämmitykseen tarvittavaa energiamäärää, joka ilmaistaan yksiköllä kWh/m² (kilowattituntia per neliömetri). Se kuvaa siis, kuinka paljon energiaa tarvitaan rakennuksen lämpötilan ylläpitämiseen.
Tämä on tärkeä mittari rakennusten energiatehokkuuden arvioinnissa, sillä:

* Pienempi lämmityskuorma tarkoittaa energiatehokkaampaa rakennusta
* Se auttaa arvioimaan rakennuksen käyttökustannuksia
* Sen avulla voidaan vertailla eri rakennusten energiatehokkuutta

Meidän mallissamme yritämme ennustaa tätä lämmityskuormaa rakennuksen ominaisuuksien perusteella, kuten:

* Rakennuksen kompaktius
* Pinta-ala, seinien ala ja katon ala
* Ikkunoiden määrä (lasitusalue)
* Rakennuksen korkeus

Tämä tieto on hyödyllinen esimerkiksi:

* Rakennusten suunnittelussa
* Energiatehokkuuden parantamisessa
* Lämmityskustannusten arvioinnissa
* Rakennusmääräysten noudattamisen arvioinnissa

## Valmistelevat toimet
"""

# yhdistetään Google Driveen
from google.colab import drive
drive.mount('/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# valitaan työskentelykansio
# %cd /gdrive/MyDrive/data

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# aineiston jako opetus- ja testidataan
from sklearn.model_selection import train_test_split

# käytettävät mallit
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

"""## Aineiston tuominen ja tarkastelu"""

# tuodaan aineisto
df = pd.read_excel('ENB2012_data.xlsx')
df.head()

# valitaan selitettäväksi muuttujaksi Y1, joten tiputetaan toinen selitettävä muuttuja pois
df = df.drop(columns=['Y2'])
# muutetaan sarakeotsikot kuvaavammiksi
df.columns = ['Suhteellinen Kompaktius', 'Pinta-ala', 'Seinän Ala', 'Katon Ala', 'Kokonaiskorkeus', 'Suuntautuminen', 'Lasitusalue', 'Lasitusalueen Jakautuminen', 'Lämmityskuorma']
df.head()

df.info()

"""Ei puuttuvia arvoja ja kaikki luvut ovat numeerisia. 9 saraketta ja 768 riviä, ei puuttuvia arvoja."""

# tarkastellaan muuttujien välisiä yhteyksiä
df.corr().round(3)

# sama korrelaatiokertoimilla
korrelaatiomatriisi = df.corr().round(2)
sns.heatmap(data=korrelaatiomatriisi, annot=True)

"""Huomataan, että osa muuttujista korreloi kohdemuuttujan kanssa heikommin (esim. Lasitusalue (0.27), Lasitusalueen Jakautuminen (0.09) ja Suuntautuminen (-0)). Tarkastellaan p-arvon avulla, mitkä muuttujat ovat merkitseviä, eli mitkä kannattaa pitää mukana."""

# nimetään selittävät muuttujat ja selitettävä muuttuja
# selittävät muuttujat
X = df[['Suhteellinen Kompaktius', 'Pinta-ala', 'Seinän Ala', 'Katon Ala',
       'Kokonaiskorkeus', 'Suuntautuminen', 'Lasitusalue',
       'Lasitusalueen Jakautuminen']]

# selitettävä muuttuja
y = df['Lämmityskuorma']

# tuodaan Statsmodels-kirjasto tilastollisten mallien rakentamista varten
import statsmodels.api as sm

# lisätään vakiotermi selittävien muuttujien matriisiin X
# tämä mahdollistaa mallin laskemisen, joka sisältää perusvaihtelun
X = sm.add_constant(X)
# Luodaan ja sovitetaan lineaarinen regressiomalli (OLS) dataan
# y on selitettävä muuttuja ja X on selittävien muuttujien matriisi
malli_sm = sm.OLS(y, X).fit()
# Tulostetaan mallin yhteenveto
# Sisältää kertoimien estimoinnit, p-arvot, R^2-arvon ja muut mallin tilastolliset tunnusluvut
print(malli_sm.summary())

"""On hyvä jos p-arvot (sarake P>|t|) ovat pienempiä kuin 0.05. Tästä syystä voidaan todeta, että "Suuntautuminen" voidaan pudottaa pois selittävistä muuttujista, sillä sen p-arvo on 0,805."""

# pudotetaan turha sarake pois dataframesta
df.drop(columns=['Suuntautuminen'], inplace=True)

# tarkastellaan valittujen muuttujien välisiä yhteyksiä hajontakuvioiden avulla
sns.pairplot(df, kind='reg')

"""Viimeistä riviä tarkastellssa huomataan, että sekä positiivista että negatiivista korrelaatiota on havaittavissa.

## Aineiston jako opetus- ja testidataan
"""

# tiputetaan selittävistä muuttujista X "Suuntatutuminen"
X = df[['Suhteellinen Kompaktius', 'Pinta-ala', 'Seinän Ala', 'Katon Ala',
       'Kokonaiskorkeus', 'Lasitusalue', 'Lasitusalueen Jakautuminen']]

# jako opetus- ja testidataan
X_opetus, X_testi, y_opetus, y_testi = train_test_split(X, y, random_state=2)

X_opetus.shape

X_testi.shape

"""## Mallin sovitus"""

# muodostetaan malli käyttäen opetusdataa
malli_linreg = LinearRegression().fit(X_opetus, y_opetus)

"""## Mallin tarkastelua"""

# regressiosuoran kulmakertoimet
malli_linreg.coef_

# vakiotermi
malli_linreg.intercept_

# opetusdatan selityskerroin
malli_linreg.score(X_opetus, y_opetus)

"""Opetusdatan selityskertoimen mukaan noin 92 % lämmityskuormasta voidaan selittää selittävien muuttujien vaihtelulla."""

# testidatan selityskerroin
malli_linreg.score(X_testi, y_testi)

"""Testidatan selityskerroin on aavistuksen huonompi, mutta ei kuitenkaan merkittävästi.

# Johtopäätökset: mallin hyvyys
**Hyvä malli:** Sekä opetus- että testidatan selityskertoimet ovat korkeat (>90 %), mikä viittaa siihen, että malli on tehokas ja lineaarinen lähestymistapa on soveltuva tähän dataan.

**Ei ylisovittamista:** Testidatan selityskerroin ei ole merkittävästi pienempi kuin opetusdatan, mikä viittaa siihen, että malli ei ole ylisovittanut opetusdataan.

## Ennustevirheet opetus- ja testidatalle
"""

# Luodaan rinnakkaiset kaaviot opetus- ja testidatan virheille
fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=True)

# Opetusdata
axs[0].scatter(malli_linreg.predict(X_opetus), malli_linreg.predict(X_opetus) - y_opetus)
axs[0].hlines(y=0, xmin=min(malli_linreg.predict(X_opetus)), xmax=max(malli_linreg.predict(X_opetus)), color='red', linestyles='dashed')
axs[0].set_title("Opetusdata: Ennusteiden virheet")
axs[0].set_xlabel("Ennuste")
axs[0].set_ylabel("Poikkeama todellisesta")

# Testidata
axs[1].scatter(malli_linreg.predict(X_testi), malli_linreg.predict(X_testi) - y_testi)
axs[1].hlines(y=0, xmin=min(malli_linreg.predict(X_testi)), xmax=max(malli_linreg.predict(X_testi)), color='red', linestyles='dashed')
axs[1].set_title("Testidata: Ennusteiden virheet")
axs[1].set_xlabel("Ennuste")

plt.tight_layout()
plt.show()

"""Molemmissa kaavioissa virheet näyttävät pysyvän kohtuullisella tasolla (suurin osa virheistä sijoittuu välille -5 ja +5). Tämä viittaa siihen, että malli tekee melko tarkkoja ennusteita.

Molemmissa kaavioissa ei näy systemaattista kuviota (esim. kaaren muotoa), mikä viittaa siihen, että lineaarinen malli on sopiva kyseiseen dataan.

Jos virheissä olisi selkeä kaarevuus tai jokin muu kuvio, se viittaisi siihen, että malli ei ole täysin lineaarinen, ja voitaisiin harkita toisenlaista mallia (esim. ei-lineaarista regressiota).

## Johtopäätökset: mallin hyvyys
Koska virheet eivät muodosta selvää kuviota (esim. kaarevuutta), lineaarinen malli näyttää olevan melko hyvä valinta tälle datalle.
Mahdolliset poikkeamat ovat pieniä ja satunnaisia, mikä viittaa siihen, että malli toimii hyvin.

Testidatan virheiden jakauma on hieman laajempi kuin opetusdatan, mutta ero ei ole merkittävä. Tämä viittaa siihen, että malli yleistyy hyvin myös uuteen dataan.
"""

# tarkastellaan virheiden jakaumaa vielä histogrammilla
fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=True)

sns.histplot(malli_linreg.predict(X_opetus) - y_opetus, ax=axs[0])
axs[0].set_title("Opetusdata: Ennusteiden virhejakauma")
axs[0].set_xlabel("Ennustevirhe")
axs[0].set_ylabel("Havaintojen määrä")

sns.histplot(malli_linreg.predict(X_testi) - y_testi, ax=axs[1])
axs[1].set_title("Testidata: Ennusteiden virhejakauma")
axs[1].set_xlabel("Ennustevirhe")
axs[1].set_ylabel("Havaintojen määrä")

"""Mallin ennustevirheet ovat keskittyneet nollan ympärille, mikä viittaa siihen, ettei malli tee systemaattisia yli- tai aliarviointeja. Testidatassa virhejakauma on hieman laajempi kuin opetusdatassa, mutta tämä on odotettavaa ja osoittaa, että malli yleistää kohtuullisen hyvin uuteen dataan.

## Todellisen kohdemuuttujan arvon ja mallin antamien ennusteiden vastaavuus pistekaaviona
"""

# Luodaan rinnakkaiset kaaviot opetus- ja testidatan virheille
fig, axs = plt.subplots(1, 2, figsize=(12, 6))

axs[0].scatter(y_opetus, malli_linreg.predict(X_opetus))
axs[0].set_title("Opetusdata: Todelliset vs ennusteet")
axs[0].plot([min(y_opetus), max(y_opetus)], [min(y_opetus), max(y_opetus)], color='red', linestyle='dashed')
axs[0].set_xlabel("Todelliset arvot")
axs[0].set_ylabel("Ennustetut arvot")

axs[1].scatter(y_testi, malli_linreg.predict(X_testi))
axs[1].set_title("Testidata: Todelliset vs ennusteet")
axs[1].plot([min(y_testi), max(y_testi)], [min(y_testi), max(y_testi)], color='red', linestyle='dashed')
axs[1].set_xlabel("Todelliset arvot")
axs[1].set_ylabel("Ennustetut arvot")

"""# Johtopäätökset: mallin hyvyys
Opetusdatassa ja testidatassa pisteet sijoittuvat tiiviisti diagonaaliviivan ympärille, mikä osoittaa, että ennusteet korreloivat vahvasti todellisten arvojen kanssa.
Tämä viittaa siihen, että lineaarinen malli selittää lämmityskuorman vaihtelut hyvin.

Opetusdatan ja testidatan kuviot ovat hyvin samankaltaisia, mikä osoittaa, että malli ei ole ylisovittunut, vaan yleistyy hyvin uuteen dataan.
Selkeä lineaarinen trendi:

Pisteiden sijoittuminen lähelle regressiosuoraa osoittaa, että malli on kyennyt oppimaan lineaarisen riippuvuuden tehokkaasti.

## Extra: ennusteet

Normalisoin datan ensin, koska muuten ennusteista ei tullut järkeviä lukuja.
Normalisointia tarvitaan, kun datassa on muuttujia eri skaaloilla. Tässä tapauksessa meillä oli:

* Isoja arvoja, kuten pinta-ala ja seinän ala


* Pieniä arvoja, kuten suhteellinen kompaktius ja lasitusalue

Nämä suuret erot voivat aiheuttaa ongelmia mallille, koska suuremman skaalan muuttujat saavat suhteettoman suuren painoarvon, jolloin mallin kertoimien tulkinta vaikeutuu. Numeerinen epävakaus voi siis johtaa huonoihin ennusteisiin.
"""

# data uudelle neljälle kiinteistölle
Xuudet = pd.DataFrame([
    [0.76, 671.0, 318, 176.0, 5.2, 0.23, 2.8],  # ensimmäisen kiinteistön tiedot
    [0.95, 520.0, 300, 110.0, 8.0, 0.0, 1]   # toisen kiinteistön tiedot
], columns=['Suhteellinen Kompaktius', 'Pinta-ala', 'Seinän Ala', 'Katon Ala', 'Kokonaiskorkeus', 'Lasitusalue', 'Lasitusalueen Jakautuminen'])
Xuudet

from sklearn.preprocessing import StandardScaler

# luodaan skaalari
scaler = StandardScaler()

# skaalataan opetusdata
X_opetus_scaled = scaler.fit_transform(X_opetus)

# luodaan ja sovitetaan malli skaalatulla datalla
malli_linreg = LinearRegression().fit(X_opetus_scaled, y_opetus)

# skaalataan uusi data samalla skaalarilla
Xuudet_scaled = scaler.transform(Xuudet[['Suhteellinen Kompaktius', 'Pinta-ala', 'Seinän Ala', 'Katon Ala', 'Kokonaiskorkeus', 'Lasitusalue', 'Lasitusalueen Jakautuminen']])

# Tehdään ennusteet skaalatulla datalla
ennusteet = malli_linreg.predict(Xuudet_scaled).round(2)

# ennusteet dataframeen
Xuudet['Ennuste'] = ennusteet
Xuudet

"""# Johtopäätös
Malli on kokonaisuudessaan erittäin hyvä lämmityskuorman ennustamiseen:

* Korkea selitysaste (>90%)
* Pienet ja satunnaiset ennustevirheet
* Hyvä yleistyvyys uuteen dataan
* Selkeä lineaarinen riippuvuussuhde
* Tilastollisesti merkitsevät muuttujat

Mallia voidaan luotettavasti käyttää lämmityskuorman ennustamiseen rakennuksen ominaisuuksien perusteella.
"""

